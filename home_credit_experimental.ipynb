{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd02ce493e2527a051d9171a5ae408aaabdea220e44952a3c04bc4bf642b6fbb1bb",
   "display_name": "Python 3.7.7 64-bit ('Tensor': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_train = pd.read_csv('home_credit_train_engineered.csv')\n",
    "\n",
    "df_train.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining features\n",
    "features = [f for f in df_train.columns if f not in ['Unnamed: 0','TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting train test splits and scaling data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "df_train[features], df_train['TARGET'], test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original train set shape: 6951\nResample train set shape : 1460\n"
     ]
    }
   ],
   "source": [
    "# Getting undersampled data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\n",
    "x_u, y_u = rus.fit_resample(x_train, y_train)\n",
    "\n",
    "print('Original train set shape:', len(x_train))\n",
    "print('Resample train set shape :', len(x_u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original train set shape: 6951\nResample train set shape : 12442\n"
     ]
    }
   ],
   "source": [
    "# Getting oversampled data\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_o, y_o = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "print('Original train set shape:', len(x_train))\n",
    "print('Resample train set shape :', len(x_o))\n",
    "\n",
    "\n",
    "\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_sm.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_classifier(clf,x_train = x_train,y_train = y_train,x_test = x_test,y_test = y_test):\n",
    "    \n",
    "    print(\"Classification on data from dataset\\n\")\n",
    "    clf.fit(x_train,y_train)\n",
    "    print(\"\\n\\nTraining report\")\n",
    "    train_report = classification_report(y_train,clf.predict(x_train))\n",
    "    print(train_report)\n",
    "    print(\"\\n\\nTesting report\")\n",
    "    test_report = classification_report(y_test,clf.predict(x_test))\n",
    "    print(test_report)\n",
    "    roc = roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1])\n",
    "    print('\\n\\nThe ROC AUC score is : ',roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampled_classifier(clf,x_u = x_u,y_u = y_u,x_test = x_test,y_test = y_test):\n",
    "    print(\"Classification on undersampled data\\n\")\n",
    "    clf.fit(x_u,y_u)\n",
    "    print(\"\\n\\nTraining report\")\n",
    "    train_report = classification_report(y_u,clf.predict(x_u))\n",
    "    print(train_report)\n",
    "    print(\"\\n\\nTesting report\")\n",
    "    test_report = classification_report(y_test,clf.predict(x_test))\n",
    "    print(test_report)\n",
    "    roc = roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1])\n",
    "    print('\\n\\nThe ROC AUC score is : ',roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampled_classifier(clf,x_o=x_o,y_=y_o,x_test=x_test,y_test=y_test):\n",
    "    print(\"\\n\\n For Oversampled data\\n\")\n",
    "    clf.fit(x_o,y_o)\n",
    "    print(\"\\n\\nTraining report\")\n",
    "    train_report = classification_report(y_o,clf.predict(x_o))\n",
    "    print(train_report)\n",
    "    print(\"\\n\\nTesting report\")\n",
    "    test_report = classification_report(y_test,clf.predict(x_test))\n",
    "    print(test_report)\n",
    "    roc = roc_auc_score(y_test, clf.predict_proba(x_test)[:, 1])\n",
    "    print('\\n\\nThe ROC AUC score is : ',roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM classifier\n",
    "import lightgbm as ltb\n",
    "model = ltb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on data from dataset\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6221\n",
      "         1.0       1.00      0.97      0.98       730\n",
      "\n",
      "    accuracy                           1.00      6951\n",
      "   macro avg       1.00      0.98      0.99      6951\n",
      "weighted avg       1.00      1.00      1.00      6951\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95      3094\n",
      "         1.0       0.42      0.05      0.10       331\n",
      "\n",
      "    accuracy                           0.90      3425\n",
      "   macro avg       0.66      0.52      0.52      3425\n",
      "weighted avg       0.86      0.90      0.87      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7244339985587541\n"
     ]
    }
   ],
   "source": [
    "normal_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on undersampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       730\n",
      "         1.0       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.64      0.76      3094\n",
      "         1.0       0.17      0.69      0.27       331\n",
      "\n",
      "    accuracy                           0.64      3425\n",
      "   macro avg       0.56      0.67      0.52      3425\n",
      "weighted avg       0.88      0.64      0.72      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7277402711026311\n"
     ]
    }
   ],
   "source": [
    "undersampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " For Oversampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      6221\n",
      "         1.0       1.00      0.98      0.99      6221\n",
      "\n",
      "    accuracy                           0.99     12442\n",
      "   macro avg       0.99      0.99      0.99     12442\n",
      "weighted avg       0.99      0.99      0.99     12442\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95      3094\n",
      "         1.0       0.39      0.08      0.14       331\n",
      "\n",
      "    accuracy                           0.90      3425\n",
      "   macro avg       0.65      0.54      0.54      3425\n",
      "weighted avg       0.86      0.90      0.87      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7363125589533979\n"
     ]
    }
   ],
   "source": [
    "oversampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma='auto',probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on data from dataset\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      6221\n",
      "         1.0       1.00      0.02      0.03       730\n",
      "\n",
      "    accuracy                           0.90      6951\n",
      "   macro avg       0.95      0.51      0.49      6951\n",
      "weighted avg       0.91      0.90      0.85      6951\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      3094\n",
      "         1.0       0.00      0.00      0.00       331\n",
      "\n",
      "    accuracy                           0.90      3425\n",
      "   macro avg       0.45      0.50      0.47      3425\n",
      "weighted avg       0.82      0.90      0.86      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.6672782522258265\n"
     ]
    }
   ],
   "source": [
    "normal_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on undersampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.82      0.83       730\n",
      "         1.0       0.83      0.85      0.84       730\n",
      "\n",
      "    accuracy                           0.83      1460\n",
      "   macro avg       0.84      0.83      0.83      1460\n",
      "weighted avg       0.84      0.83      0.83      1460\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.63      0.76      3094\n",
      "         1.0       0.17      0.72      0.28       331\n",
      "\n",
      "    accuracy                           0.64      3425\n",
      "   macro avg       0.56      0.67      0.52      3425\n",
      "weighted avg       0.88      0.64      0.71      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7254163110747436\n"
     ]
    }
   ],
   "source": [
    "undersampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " For Oversampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94      6221\n",
      "         1.0       0.92      0.97      0.95      6221\n",
      "\n",
      "    accuracy                           0.94     12442\n",
      "   macro avg       0.95      0.94      0.94     12442\n",
      "weighted avg       0.95      0.94      0.94     12442\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89      3094\n",
      "         1.0       0.21      0.34      0.26       331\n",
      "\n",
      "    accuracy                           0.81      3425\n",
      "   macro avg       0.57      0.60      0.57      3425\n",
      "weighted avg       0.85      0.81      0.83      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.6797627021991692\n"
     ]
    }
   ],
   "source": [
    "oversampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on data from dataset\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6221\n",
      "         1.0       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      6951\n",
      "   macro avg       1.00      1.00      1.00      6951\n",
      "weighted avg       1.00      1.00      1.00      6951\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.90      0.90      3094\n",
      "         1.0       0.15      0.17      0.16       331\n",
      "\n",
      "    accuracy                           0.83      3425\n",
      "   macro avg       0.53      0.53      0.53      3425\n",
      "weighted avg       0.84      0.83      0.83      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.5333639614339809\n"
     ]
    }
   ],
   "source": [
    "normal_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on undersampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       730\n",
      "         1.0       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.53      0.68      3094\n",
      "         1.0       0.12      0.61      0.21       331\n",
      "\n",
      "    accuracy                           0.54      3425\n",
      "   macro avg       0.53      0.57      0.44      3425\n",
      "weighted avg       0.85      0.54      0.63      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.5739380576771727\n"
     ]
    }
   ],
   "source": [
    "undersampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " For Oversampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6221\n",
      "         1.0       1.00      1.00      1.00      6221\n",
      "\n",
      "    accuracy                           1.00     12442\n",
      "   macro avg       1.00      1.00      1.00     12442\n",
      "weighted avg       1.00      1.00      1.00     12442\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87      3094\n",
      "         1.0       0.13      0.25      0.17       331\n",
      "\n",
      "    accuracy                           0.77      3425\n",
      "   macro avg       0.52      0.54      0.52      3425\n",
      "weighted avg       0.84      0.77      0.80      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.5381119680035621\n"
     ]
    }
   ],
   "source": [
    "oversampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Without sampling\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=x_train[0].shape),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "\n",
      "\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97      6221\n",
      "         1.0       0.94      0.45      0.61       730\n",
      "\n",
      "    accuracy                           0.94      6951\n",
      "   macro avg       0.94      0.73      0.79      6951\n",
      "weighted avg       0.94      0.94      0.93      6951\n",
      "\n",
      "Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94      3094\n",
      "         1.0       0.30      0.08      0.12       331\n",
      "\n",
      "    accuracy                           0.89      3425\n",
      "   macro avg       0.61      0.53      0.53      3425\n",
      "weighted avg       0.85      0.89      0.86      3425\n",
      "\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "ROC AUC Score : 0.6963560697344241\n"
     ]
    }
   ],
   "source": [
    "c = classification_report(y_train,model.predict_classes(x_train))\n",
    "print(\"\\n\\nTraining\\n\",c)\n",
    "c = classification_report(y_test,model.predict_classes(x_test))\n",
    "print(\"Testing\\n\",c)\n",
    "roc = roc_auc_score(y_test,model.predict_proba(x_test))\n",
    "print(\"ROC AUC Score :\",roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27885e370c8>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# With undersampling\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=x_u[0].shape),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')\n",
    "model.fit(x_u,y_u,validation_data=(x_test,y_test),epochs=10,verbose = 5)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       730\n",
      "         1.0       0.95      0.92      0.93       730\n",
      "\n",
      "    accuracy                           0.93      1460\n",
      "   macro avg       0.94      0.93      0.93      1460\n",
      "weighted avg       0.94      0.93      0.93      1460\n",
      "\n",
      "Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.65      0.77      3094\n",
      "         1.0       0.17      0.65      0.26       331\n",
      "\n",
      "    accuracy                           0.65      3425\n",
      "   macro avg       0.56      0.65      0.52      3425\n",
      "weighted avg       0.87      0.65      0.72      3425\n",
      "\n",
      "ROC AUC Score : 0.6955651421619077\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "c = classification_report(y_u,model.predict_classes(x_u))\n",
    "print(\"Training\\n\",c)\n",
    "c = classification_report(y_test,model.predict_classes(x_test))\n",
    "print(\"Testing\\n\",c)\n",
    "roc = roc_auc_score(y_test,model.predict_proba(x_test))\n",
    "print(\"ROC AUC Score :\",roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2788c471b88>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# With oversampling\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=x_o[0].shape),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')\n",
    "model.fit(x_o,y_o,validation_data=(x_test,y_test),epochs=10,verbose = 5)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      6221\n",
      "         1.0       0.99      0.99      0.99      6221\n",
      "\n",
      "    accuracy                           0.99     12442\n",
      "   macro avg       0.99      0.99      0.99     12442\n",
      "weighted avg       0.99      0.99      0.99     12442\n",
      "\n",
      "Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.93      0.92      3094\n",
      "         1.0       0.21      0.18      0.19       331\n",
      "\n",
      "    accuracy                           0.86      3425\n",
      "   macro avg       0.56      0.55      0.56      3425\n",
      "weighted avg       0.85      0.86      0.85      3425\n",
      "\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Manas Vardhan\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "ROC AUC Score : 0.6801254547833542\n"
     ]
    }
   ],
   "source": [
    "c = classification_report(y_o,model.predict_classes(x_o))\n",
    "print(\"Training\\n\",c)\n",
    "c = classification_report(y_test,model.predict_classes(x_test))\n",
    "print(\"Testing\\n\",c)\n",
    "roc = roc_auc_score(y_test,model.predict_proba(x_test))\n",
    "print(\"ROC AUC Score :\",roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on data from dataset\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.95      6221\n",
      "         1.0       0.62      0.11      0.18       730\n",
      "\n",
      "    accuracy                           0.90      6951\n",
      "   macro avg       0.76      0.55      0.56      6951\n",
      "weighted avg       0.87      0.90      0.87      6951\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95      3094\n",
      "         1.0       0.40      0.08      0.13       331\n",
      "\n",
      "    accuracy                           0.90      3425\n",
      "   macro avg       0.65      0.53      0.54      3425\n",
      "weighted avg       0.86      0.90      0.87      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7267189004349126\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "normal_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on undersampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76       730\n",
      "         1.0       0.76      0.75      0.76       730\n",
      "\n",
      "    accuracy                           0.76      1460\n",
      "   macro avg       0.76      0.76      0.76      1460\n",
      "weighted avg       0.76      0.76      0.76      1460\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.64      0.76      3094\n",
      "         1.0       0.17      0.68      0.27       331\n",
      "\n",
      "    accuracy                           0.64      3425\n",
      "   macro avg       0.56      0.66      0.51      3425\n",
      "weighted avg       0.87      0.64      0.71      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7055757464501022\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "undersampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " For Oversampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.74      0.76      6221\n",
      "         1.0       0.75      0.79      0.77      6221\n",
      "\n",
      "    accuracy                           0.76     12442\n",
      "   macro avg       0.77      0.76      0.76     12442\n",
      "weighted avg       0.77      0.76      0.76     12442\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.70      0.81      3094\n",
      "         1.0       0.18      0.62      0.28       331\n",
      "\n",
      "    accuracy                           0.69      3425\n",
      "   macro avg       0.56      0.66      0.54      3425\n",
      "weighted avg       0.87      0.69      0.75      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7172014053122993\n",
      "C:\\Users\\Manas Vardhan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "oversampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on data from dataset\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6221\n",
      "         1.0       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      6951\n",
      "   macro avg       1.00      1.00      1.00      6951\n",
      "weighted avg       1.00      1.00      1.00      6951\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      3094\n",
      "         1.0       1.00      0.00      0.01       331\n",
      "\n",
      "    accuracy                           0.90      3425\n",
      "   macro avg       0.95      0.50      0.48      3425\n",
      "weighted avg       0.91      0.90      0.86      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.6998132043893551\n"
     ]
    }
   ],
   "source": [
    "normal_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification on undersampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       730\n",
      "         1.0       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.65      0.77      3094\n",
      "         1.0       0.17      0.67      0.27       331\n",
      "\n",
      "    accuracy                           0.65      3425\n",
      "   macro avg       0.56      0.66      0.52      3425\n",
      "weighted avg       0.87      0.65      0.72      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7213625631521491\n"
     ]
    }
   ],
   "source": [
    "undersampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " For Oversampled data\n",
      "\n",
      "\n",
      "\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6221\n",
      "         1.0       1.00      1.00      1.00      6221\n",
      "\n",
      "    accuracy                           1.00     12442\n",
      "   macro avg       1.00      1.00      1.00     12442\n",
      "weighted avg       1.00      1.00      1.00     12442\n",
      "\n",
      "\n",
      "\n",
      "Testing report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.98      0.94      3094\n",
      "         1.0       0.29      0.08      0.13       331\n",
      "\n",
      "    accuracy                           0.89      3425\n",
      "   macro avg       0.60      0.53      0.53      3425\n",
      "weighted avg       0.85      0.89      0.86      3425\n",
      "\n",
      "\n",
      "\n",
      "The ROC AUC score is :  0.7005182040280672\n"
     ]
    }
   ],
   "source": [
    "oversampled_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}